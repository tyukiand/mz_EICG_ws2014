\documentclass{scrartcl}

\input{./packages}
\input{./definitions}
\newcommand{\exercise}[2]{\vspace{1em}\noindent{\bf Exercise #1 (#2)}}
\renewcommand{\proof}{\vspace{0.8em}\noindent{\bf Proof: }}

\begin{document}
\noindent{\footnotesize Computer Graphics 2014/15, Exercise 7} 
\hfill 
{\footnotesize \input{./currentDate.txt}}
\newline
{\footnotesize \input{../../NAMES.txt}}

\noindent\hrulefill

\exercise{7.1}{SLERP}
Let $(X, \scalar{-}{-})$ be an arbitrary scalar product space
and $\norm{-}$ the induced norm:
\[
  \norm{x} := \sqrt{\scalar{x}{x}}.
\]
In particular, $X$ can be $\Real^4 \iso \Quaternion$ with the
standard scalar product.

Let $a,b\in X$ be two different unit vectors and $\phi$ the 
positive angle from $(0, 2\pi)$ such that 
$\cos(\phi) = \scalar{a}{b}$.
Consider the following function:
\[
    slerp(a, b, t) := 
    \frac{\sin\rPar{(1-t)\phi}}{\sin{\phi}} a +
    \frac{\sin\rPar{t\phi}}{\sin{\phi}} b,
\]
where $t\in [0, 1]$.
We claim that this is a linear angular interpolation
between $a$ and $b$.

\noindent \textbf{Proof: } We define a unit vector orthogonal
to $a$ as follows:
\[
  u := \frac{b - \scalar{a}{b}a}{\norm{b - \scalar{a}{b}a}},
\]
this can be seen as a single step of Gram-Schmidt
orthogonalization on the basis $\set{a, b}$.
We want to simplify the denominator, so we compute:
\[
  \norm{b - \scalar{a}{b}a}^2 
  = 1 - 2\scalar{a}{b}^2 + \scalar{a}{b}^2
  = 1 - \rPar{\cos(\phi)}^2 
  = \rPar{\sin(\phi)}^2,
\]
this allows us to express $u$ as follows:
\[
  u = \frac{b - \cos(\phi)a}{\sin(\phi)}.
\]
Now $\set{a, u}$ is an orthonormal basis, so we can 
express $b$ as follows:
\[
  b = \scalar{a}{b}a + \scalar{u}{b}u.
\]
The first coordinate is by definition just $\cos(\phi)$,
the second coordinate can be computed as follows:
\[
  \scalar{u}{b} 
  = \frac{1}{\sin(\phi)}\scalar{b - \cos(\phi)a}{b}
  = \frac{1}{\sin(\phi)}\rPar{\norm{b}^2 - (\cos(\phi))^2} 
  = \sin(\phi).
\]
This gives us a simple description of $b$ in terms of
$a$ and $u$:
\[
  b = \cos(\phi)a + \sin(\phi)u.
\]
Now all we have to do is to plug it into the $slerp$ formula:
\begin{align*}
  slerp(a, b, t) 
    &= \frac{\sin((1-t)\phi)}{\sin(\phi)} a + 
       \frac{\sin(t\phi)}{\sin(\phi)} b \\
    &= \frac{\sin((1-t)\phi) + \sin(t\phi)\cos(\phi)}{\sin(\phi)}
       a + \sin(\phi t) u \\
    &= \frac{-\cos(\phi)\sin(t\phi) + \sin(\phi)\cos(t\phi)
              + \sin(t\phi)\cos(\phi)
        }{\sin(\phi)} a  + \sin(t\phi) u \\
    &= \cos(t\phi)a + \sin(t\phi)u.
\end{align*}
Here we used the addition theorem for $\sin$ in the third line.
\hfill \qed

\exercise{7.2}{SLERP + trackball} See code.
Note that $slerp$ and Euler angle interpolation is activated by 
pressing S or E.

\exercise{7.3}{Symmetry: technical details of a proof}
Let $u_i,v_i\in \Real^3$ for all $i\in 0 \dots n$ for some
$n\in\Natural$.
We consider the following matrices:
\[
  U_i = \mat{cc}{0 & -u_i^T \\ u_i & -[u_i]_\cross}
  \quad
  V_i = \mat{cc}{0 & -v_i^T \\ v_i & [v_i]_\cross}
\]
and claim that 
\[
  \sum_{i=1}^n U_i^T V_i
\]
is symmetric.
For this it is obviously sufficient to show that each 
summand $U_i^T V_i$ is symmetric. Let $u\in\set{u_i}_i$
and $v\in\set{v_i}_i$ be some vectors and $U, V$ matrices
as above, but without the indices.

It holds:
\begin{align*}
  \mat{cc}{0 & -u^T \\ u & -[u]_\cross}^T
  \mat{cc}{0 & -v^T \\ v & [v]_\cross} 
  &= 
  \mat{cc}{0 & u^T \\ -u & [u]_\cross}
  \mat{cc}{0 & -v^T \\ v & [v]_\cross} \\
  &= 
  \mat{cc}{
    u^T v & (u\cross v)^T \\
    u\cross v & uv^T + vu^T + u^Tv I
  }
\end{align*}
Here we used the following identity in first row, second column:
\[
  u^T[v]_\cross = ([v]_\cross^Tu)^T = 
  (-v\cross u)^T = (u\cross v)^T 
\]
and the matrix-version of the BAC-CAB-rule in the lower right 
corner:
\[
  [a]_\cross[b]_\cross = ba^T - b^Ta I.
\]
The resulting matrix is obviously symmetric, therefore 
the sum of such symmetric matrices is also symmetric.
\hfill \qed

\exercise{7.4}{Data registration / Image registration}
Code incomplete. No matrix addition or eigenvector implementation
found. Please tell to use something like MATLAB next time the 
homework is not solvable with available tools.

\end{document}
